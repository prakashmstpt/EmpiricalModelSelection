{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b814269b-b079-43c8-bf4b-ea5c4ef23d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['REQUESTS_CA_BUNDLE'] = '/Users/XXXXXX/MSPref/Transformers/hf.pem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28fdfa2-8704-40ff-af8a-eb30da049638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare a basic Hugging face pipeline for NER using dbmdz/bert-large-cased-finetuned-conll03-english \n",
    "##  24 x BertLayer - Total params: 332,538,889 \n",
    "## dslim/bert-base-NER is fine tuned on https://huggingface.co/datasets/conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7f661f-641a-4183-b268-238386b74e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99938285,\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99815494,\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99590707,\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99923277,\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931,\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.976115,\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887976,\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9932105,\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import time\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "#nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer , aggregation_strategy=\"simple\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "nlp(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
    "#nlp(\"LONDON 1996-08-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9069fed3-ed96-441f-8604-e63d4b5d13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes input record - '11\\tCRICKET\\t-\\tLEICESTERSHIRE\\tTAKE\\tOVER\\tAT\\tTOP\\tAFTER\\tINNINGS\\tVICTORY\\t.\\t0\\t0\\t3\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\n'\n",
    "# Truncate new line and split by tab and add whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b30517-553f-46a8-ae62-2835df3b7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_record_to_infer_data(record):\n",
    "    record = record.strip()\n",
    "    record = record.split(\"\\t\")\n",
    "    #record = tf.strings.split(record, sep=\"\\t\")\n",
    "    length = int(record[0])\n",
    "    tokens = record[1 : length + 1]\n",
    "    pri_sentence = \"\"\n",
    "    for tk in tokens:\n",
    "        pri_sentence += tk\n",
    "        pri_sentence += \" \"\n",
    "    pri_sentence = pri_sentence.strip()\n",
    "    tags = record[length + 1 :]\n",
    "    #tags = tf.strings.to_number(tags, out_type=tf.int64)\n",
    "    tags = [int(i) for i in tags]\n",
    "    #tags += 1\n",
    "    return pri_sentence, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92734185-88d4-480b-98c7-fb122cd1b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_file=\"/Users/XXXXXX/MSPref/Transformers/LLM/conlldata/conll_val.txt\"\n",
    "f=open(val_data_file)\n",
    "val_data=f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5299454-c8fc-4ea3-b601-9ce04d34f9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11\\tCRICKET\\t-\\tLEICESTERSHIRE\\tTAKE\\tOVER\\tAT\\tTOP\\tAFTER\\tINNINGS\\tVICTORY\\t.\\t0\\t0\\t3\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d98f18-6483-4dbf-a407-11ace8bbb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: 'O', 2: 'B-PER', 3: 'I-PER', 4: 'B-ORG', 5: 'I-ORG', 6: 'B-LOC', 7: 'I-LOC', 8: 'B-MISC', 9: 'I-MISC'}\n"
     ]
    }
   ],
   "source": [
    "def make_tag_lookup_table():\n",
    "    iob_labels = [\"B\", \"I\"]\n",
    "    ner_labels = [\"PER\", \"ORG\", \"LOC\", \"MISC\"]\n",
    "    all_labels = [(label1, label2) for label2 in ner_labels for label1 in iob_labels]\n",
    "    all_labels = [\"-\".join([a, b]) for a, b in all_labels]\n",
    "    all_labels = [\"[PAD]\", \"O\"] + all_labels\n",
    "    #all_labels = [\"[PAD]\"] + all_labels\n",
    "    return dict(zip(range(0, len(all_labels) + 1), all_labels))\n",
    "\n",
    "\n",
    "nermapping = make_tag_lookup_table()\n",
    "print(nermapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1a357a-af5e-46e6-953c-cb49f082666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, 'O': 1, 'B-PER': 2, 'I-PER': 3, 'B-ORG': 4, 'I-ORG': 5, 'B-LOC': 6, 'I-LOC': 7, 'B-MISC': 8, 'I-MISC': 9}\n"
     ]
    }
   ],
   "source": [
    "nerk = dict((v,k) for k,v in nermapping.items())\n",
    "print(nerk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952e1ed1-b13c-4182-bece-e80cb5756ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pridict_ner_map(sns,priout):\n",
    "    #print(sns)\n",
    "    #print(priout)\n",
    "    snsa = sns.split(\" \")\n",
    "    priidx=[]\n",
    "    for si in snsa:\n",
    "        priidx.append(0)\n",
    "    for ners in priout:\n",
    "        #print(ners)\n",
    "        if 'index' in ners.keys() :\n",
    "            #print(ners)\n",
    "            if ners['word'] in snsa :\n",
    "                #idx=ners['index'] - 1 \n",
    "                idx=snsa.index(ners['word'])\n",
    "                #priidx[idx]= nerk[ners['entity']]\n",
    "                priidx[idx]= nerk[ners['entity']] - 1\n",
    "    #print(priidx)\n",
    "    return priidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9666deb6-6c2a-4a67-8ae4-eb1c3112bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BertForTokenClassification                              --\n",
       "├─BertModel: 1-1                                        --\n",
       "│    └─BertEmbeddings: 2-1                              --\n",
       "│    │    └─Embedding: 3-1                              29,691,904\n",
       "│    │    └─Embedding: 3-2                              524,288\n",
       "│    │    └─Embedding: 3-3                              2,048\n",
       "│    │    └─LayerNorm: 3-4                              2,048\n",
       "│    │    └─Dropout: 3-5                                --\n",
       "│    └─BertEncoder: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-6                             302,309,376\n",
       "├─Dropout: 1-2                                          --\n",
       "├─Linear: 1-3                                           9,225\n",
       "================================================================================\n",
       "Total params: 332,538,889\n",
       "Trainable params: 332,538,889\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(model)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c24fe5-5cb2-43b6-b78a-16462e1e7c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 4748 tokens with 2879 phrases; found: 4748 phrases; correct: 1180.\n",
      "accuracy:  34.88%; (non-O)\n",
      "accuracy:  27.86%; precision:  24.85%; recall:  40.99%; FB1:  30.94\n",
      "              LOC: precision:  11.52%; recall:  24.03%; FB1:  15.58  1345\n",
      "             MISC: precision:  25.62%; recall:  95.59%; FB1:  40.41  847\n",
      "              ORG: precision:  38.26%; recall:  37.98%; FB1:  38.12  1218\n",
      "              PER: precision:  25.56%; recall:  43.85%; FB1:  32.29  1338\n",
      "Total time taken  355.6348478794098\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "def calculate_metrics(dataset):\n",
    "    all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "    for recp in dataset:\n",
    "        x,y = map_record_to_infer_data(recp)\n",
    "        #inputs = tokenizer(x, return_tensors=\"pt\")\n",
    "        #outputs = model(**inputs)\n",
    "        #probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
    "        #predict = outputs.logits.argmax(dim=-1)[0].tolist()\n",
    "        output = nlp(x)\n",
    "        #output = getNERCL(x,predict, probabilities)\n",
    "        #print(output)\n",
    "        #=====\n",
    "        true_tag_ids = np.reshape(y, [-1])\n",
    "        predictions=return_pridict_ner_map(x,output)\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        #print(predictions)\n",
    "        predictions=np.reshape(predictions, [-1])\n",
    "        mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "        true_tag_ids = true_tag_ids[mask]\n",
    "        predicted_tag_ids = predictions[mask]\n",
    "        #print(true_tag_ids)\n",
    "        #print(predicted_tag_ids)\n",
    "        #====\n",
    "        all_true_tag_ids.append(true_tag_ids)\n",
    "        all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "    #if len(all_true_tag_ids) == len(all_predicted_tag_ids) :\n",
    "    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "    predicted_tags = [nermapping[tag] for tag in all_predicted_tag_ids]\n",
    "    real_tags = [nermapping[tag] for tag in all_true_tag_ids]\n",
    "        #print(unique(real_tags))\n",
    "        #print(unique(predicted_tags))\n",
    "    evaluate(real_tags, predicted_tags)\n",
    "    #else :\n",
    "        #print(len(all_true_tag_ids))\n",
    "        #print(len(all_predicted_tag_ids))\n",
    "start = time.time()\n",
    "calculate_metrics(val_data)\n",
    "end = time.time()\n",
    "print(\"Total time taken \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacea26-72a7-4302-b425-921c8f685c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
